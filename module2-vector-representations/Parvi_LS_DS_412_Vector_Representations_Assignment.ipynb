{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/job_listings.csv')\n",
    "df\n",
    "\n",
    "description_list = []\n",
    "\n",
    "# first extract the descriptions and make as a list\n",
    "for i in range(425):\n",
    "    description_list.append(df['description'][i])\n",
    "    # print(df['description'][i])\n",
    "\n",
    "len(description_list) # 425 list items\n",
    "\n",
    "# write a function to remove all the tags using BeautifulSoup\n",
    "def html_to_text(text):\n",
    "    soup = BeautifulSoup(text)\n",
    "    return soup.get_text()\n",
    "    # print()\n",
    "    # print(df['description'][0])\n",
    "\n",
    "# make a new DataFrame and overwrite the description column with data without html tags \n",
    "df_new = df.copy()\n",
    "df_new['description'] = df_new['description'].apply(html_to_text)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0                                        description  \\\n",
       "0             0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1             1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2             2  b'As a Data Scientist you will be working on c...   \n",
       "3             3  b'$4,969 - $6,756 a monthContractUnder the gen...   \n",
       "4             4  b'Location: USA \\xe2\\x80\\x93 multiple location...   \n",
       "..          ...                                                ...   \n",
       "421         421  b\"About Us:\\nWant to be part of a fantastic an...   \n",
       "422         422  b'InternshipAt Uber, we ignite opportunity by ...   \n",
       "423         423  b'$200,000 - $350,000 a yearA million people a...   \n",
       "424         424  b\"SENIOR DATA SCIENTIST\\nJOB DESCRIPTION\\n\\nAB...   \n",
       "425         425  b'Cerner Intelligence is a new, innovative org...   \n",
       "\n",
       "                                                 title  \n",
       "0                                      Data scientist   \n",
       "1                                     Data Scientist I  \n",
       "2                         Data Scientist - Entry Level  \n",
       "3                                       Data Scientist  \n",
       "4                                       Data Scientist  \n",
       "..                                                 ...  \n",
       "421                       Senior Data Science Engineer  \n",
       "422  2019 PhD Data Scientist Internship - Forecasti...  \n",
       "423                         Data Scientist - Insurance  \n",
       "424                              Senior Data Scientist  \n",
       "425                                     Data Scientist  \n",
       "\n",
       "[426 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>description</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n      <td>Data scientist</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n      <td>Data Scientist I</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b'As a Data Scientist you will be working on c...</td>\n      <td>Data Scientist - Entry Level</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>421</td>\n      <td>b\"About Us:\\nWant to be part of a fantastic an...</td>\n      <td>Senior Data Science Engineer</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>422</td>\n      <td>b'InternshipAt Uber, we ignite opportunity by ...</td>\n      <td>2019 PhD Data Scientist Internship - Forecasti...</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>423</td>\n      <td>b'$200,000 - $350,000 a yearA million people a...</td>\n      <td>Data Scientist - Insurance</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>424</td>\n      <td>b\"SENIOR DATA SCIENTIST\\nJOB DESCRIPTION\\n\\nAB...</td>\n      <td>Senior Data Scientist</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>425</td>\n      <td>b'Cerner Intelligence is a new, innovative org...</td>\n      <td>Data Scientist</td>\n    </tr>\n  </tbody>\n</table>\n<p>426 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0                                        description  \\\n",
       "0             0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1             1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2             2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3             3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4             4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "..          ...                                                ...   \n",
       "421         421  b\"<b>About Us:</b><br/>\\nWant to be part of a ...   \n",
       "422         422  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "423         423  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "424         424  b\"<p></p><div><p>SENIOR DATA SCIENTIST</p><p>\\...   \n",
       "425         425  b'<div></div><div><div><div><div><p>Cerner Int...   \n",
       "\n",
       "                                                 title  \n",
       "0                                      Data scientist   \n",
       "1                                     Data Scientist I  \n",
       "2                         Data Scientist - Entry Level  \n",
       "3                                       Data Scientist  \n",
       "4                                       Data Scientist  \n",
       "..                                                 ...  \n",
       "421                       Senior Data Science Engineer  \n",
       "422  2019 PhD Data Scientist Internship - Forecasti...  \n",
       "423                         Data Scientist - Insurance  \n",
       "424                              Senior Data Scientist  \n",
       "425                                     Data Scientist  \n",
       "\n",
       "[426 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>description</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n      <td>Data scientist</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n      <td>Data Scientist I</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n      <td>Data Scientist - Entry Level</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>421</td>\n      <td>b\"&lt;b&gt;About Us:&lt;/b&gt;&lt;br/&gt;\\nWant to be part of a ...</td>\n      <td>Senior Data Science Engineer</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>422</td>\n      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n      <td>2019 PhD Data Scientist Internship - Forecasti...</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>423</td>\n      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n      <td>Data Scientist - Insurance</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>424</td>\n      <td>b\"&lt;p&gt;&lt;/p&gt;&lt;div&gt;&lt;p&gt;SENIOR DATA SCIENTIST&lt;/p&gt;&lt;p&gt;\\...</td>\n      <td>Senior Data Scientist</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>425</td>\n      <td>b'&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;Cerner Int...</td>\n      <td>Data Scientist</td>\n    </tr>\n  </tbody>\n</table>\n<p>426 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0                                        description  \\\n",
       "0             0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1             1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2             2  b'As a Data Scientist you will be working on c...   \n",
       "3             3  b'$4,969 - $6,756 a monthContractUnder the gen...   \n",
       "4             4  b'Location: USA \\xe2\\x80\\x93 multiple location...   \n",
       "..          ...                                                ...   \n",
       "421         421  b\"About Us:\\nWant to be part of a fantastic an...   \n",
       "422         422  b'InternshipAt Uber, we ignite opportunity by ...   \n",
       "423         423  b'$200,000 - $350,000 a yearA million people a...   \n",
       "424         424  b\"SENIOR DATA SCIENTIST\\nJOB DESCRIPTION\\n\\nAB...   \n",
       "425         425  b'Cerner Intelligence is a new, innovative org...   \n",
       "\n",
       "                                                 title  \n",
       "0                                      Data scientist   \n",
       "1                                     Data Scientist I  \n",
       "2                         Data Scientist - Entry Level  \n",
       "3                                       Data Scientist  \n",
       "4                                       Data Scientist  \n",
       "..                                                 ...  \n",
       "421                       Senior Data Science Engineer  \n",
       "422  2019 PhD Data Scientist Internship - Forecasti...  \n",
       "423                         Data Scientist - Insurance  \n",
       "424                              Senior Data Scientist  \n",
       "425                                     Data Scientist  \n",
       "\n",
       "[426 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>description</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n      <td>Data scientist</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n      <td>Data Scientist I</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b'As a Data Scientist you will be working on c...</td>\n      <td>Data Scientist - Entry Level</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>421</td>\n      <td>b\"About Us:\\nWant to be part of a fantastic an...</td>\n      <td>Senior Data Science Engineer</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>422</td>\n      <td>b'InternshipAt Uber, we ignite opportunity by ...</td>\n      <td>2019 PhD Data Scientist Internship - Forecasti...</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>423</td>\n      <td>b'$200,000 - $350,000 a yearA million people a...</td>\n      <td>Data Scientist - Insurance</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>424</td>\n      <td>b\"SENIOR DATA SCIENTIST\\nJOB DESCRIPTION\\n\\nAB...</td>\n      <td>Senior Data Scientist</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>425</td>\n      <td>b'Cerner Intelligence is a new, innovative org...</td>\n      <td>Data Scientist</td>\n    </tr>\n  </tbody>\n</table>\n<p>426 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "\n",
    "# load the spacy models\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# nlp.disable_pipes('tagger', 'parser')\n",
    "spacy_tokens = []\n",
    "\n",
    "# run a loop for each cell of df['description'] and use in the pipe\n",
    "for doc in nlp.pipe(df_new['description'], disable=['tagger', 'parser', 'ner', 'lemmatizer']):\n",
    "    doc_token = []\n",
    "\n",
    "    # each document's word is tokenized tokenized and added to the list \n",
    "    for token in doc:\n",
    "        doc_token.append(token.text)\n",
    "    \n",
    "    # for each document tokenized put it in spacy_token list\n",
    "    spacy_tokens.append(doc_token) \n",
    "\n",
    "df_new['spacy_token'] = spacy_tokens\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0                                        description  \\\n",
       "0             0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1             1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2             2  b'As a Data Scientist you will be working on c...   \n",
       "3             3  b'$4,969 - $6,756 a monthContractUnder the gen...   \n",
       "4             4  b'Location: USA \\xe2\\x80\\x93 multiple location...   \n",
       "..          ...                                                ...   \n",
       "421         421  b\"About Us:\\nWant to be part of a fantastic an...   \n",
       "422         422  b'InternshipAt Uber, we ignite opportunity by ...   \n",
       "423         423  b'$200,000 - $350,000 a yearA million people a...   \n",
       "424         424  b\"SENIOR DATA SCIENTIST\\nJOB DESCRIPTION\\n\\nAB...   \n",
       "425         425  b'Cerner Intelligence is a new, innovative org...   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                      Data scientist    \n",
       "1                                     Data Scientist I   \n",
       "2                         Data Scientist - Entry Level   \n",
       "3                                       Data Scientist   \n",
       "4                                       Data Scientist   \n",
       "..                                                 ...   \n",
       "421                       Senior Data Science Engineer   \n",
       "422  2019 PhD Data Scientist Internship - Forecasti...   \n",
       "423                         Data Scientist - Insurance   \n",
       "424                              Senior Data Scientist   \n",
       "425                                     Data Scientist   \n",
       "\n",
       "                                           spacy_token  \n",
       "0    [b\"Job, Requirements:\\nConceptual, understandi...  \n",
       "1    [b'Job, Description\\n\\nAs, a, Data, Scientist,...  \n",
       "2    [b'As, a, Data, Scientist, you, will, be, work...  \n",
       "3    [b'$4,969, -, $, 6,756, a, monthContractUnder,...  \n",
       "4    [b'Location, :, USA, \\xe2\\x80\\x93, multiple, l...  \n",
       "..                                                 ...  \n",
       "421  [b\"About, Us:\\nWant, to, be, part, of, a, fant...  \n",
       "422  [b'InternshipAt, Uber, ,, we, ignite, opportun...  \n",
       "423  [b'$200,000, -, $, 350,000, a, yearA, million,...  \n",
       "424  [b\"SENIOR, DATA, SCIENTIST\\nJOB, DESCRIPTION\\n...  \n",
       "425  [b'Cerner, Intelligence, is, a, new, ,, innova...  \n",
       "\n",
       "[426 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>description</th>\n      <th>title</th>\n      <th>spacy_token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n      <td>Data scientist</td>\n      <td>[b\"Job, Requirements:\\nConceptual, understandi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n      <td>Data Scientist I</td>\n      <td>[b'Job, Description\\n\\nAs, a, Data, Scientist,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b'As a Data Scientist you will be working on c...</td>\n      <td>Data Scientist - Entry Level</td>\n      <td>[b'As, a, Data, Scientist, you, will, be, work...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n      <td>Data Scientist</td>\n      <td>[b'$4,969, -, $, 6,756, a, monthContractUnder,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n      <td>Data Scientist</td>\n      <td>[b'Location, :, USA, \\xe2\\x80\\x93, multiple, l...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>421</td>\n      <td>b\"About Us:\\nWant to be part of a fantastic an...</td>\n      <td>Senior Data Science Engineer</td>\n      <td>[b\"About, Us:\\nWant, to, be, part, of, a, fant...</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>422</td>\n      <td>b'InternshipAt Uber, we ignite opportunity by ...</td>\n      <td>2019 PhD Data Scientist Internship - Forecasti...</td>\n      <td>[b'InternshipAt, Uber, ,, we, ignite, opportun...</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>423</td>\n      <td>b'$200,000 - $350,000 a yearA million people a...</td>\n      <td>Data Scientist - Insurance</td>\n      <td>[b'$200,000, -, $, 350,000, a, yearA, million,...</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>424</td>\n      <td>b\"SENIOR DATA SCIENTIST\\nJOB DESCRIPTION\\n\\nAB...</td>\n      <td>Senior Data Scientist</td>\n      <td>[b\"SENIOR, DATA, SCIENTIST\\nJOB, DESCRIPTION\\n...</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>425</td>\n      <td>b'Cerner Intelligence is a new, innovative org...</td>\n      <td>Data Scientist</td>\n      <td>[b'Cerner, Intelligence, is, a, new, ,, innova...</td>\n    </tr>\n  </tbody>\n</table>\n<p>426 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(426, 20)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   applicants  applied  better  decision  deep  digital  diverse  engineers  \\\n",
       "0           0        0       0         1     0        0        0          0   \n",
       "1           0        0       0         0     0        0        0          0   \n",
       "2           0        1       0         0     0        0        0          0   \n",
       "3           1        0       0         0     0        0        0          0   \n",
       "4           0        0       0         0     0        0        0          0   \n",
       "\n",
       "   global  growth  intelligence  internal  job  like  model  platform  \\\n",
       "0       0       0             0         0    0     2      1         0   \n",
       "1       0       0             0         0    0     0      0         0   \n",
       "2       0       0             0         0    1     0      0         0   \n",
       "3       0       0             0         0    0     0      0         0   \n",
       "4       0       0             0         0    0     0      0         0   \n",
       "\n",
       "   position  processing  project  required  \n",
       "0         0           0        0         0  \n",
       "1         0           0        0         0  \n",
       "2         1           0        0         0  \n",
       "3         0           0        0         1  \n",
       "4         0           0        0         0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>applicants</th>\n      <th>applied</th>\n      <th>better</th>\n      <th>decision</th>\n      <th>deep</th>\n      <th>digital</th>\n      <th>diverse</th>\n      <th>engineers</th>\n      <th>global</th>\n      <th>growth</th>\n      <th>intelligence</th>\n      <th>internal</th>\n      <th>job</th>\n      <th>like</th>\n      <th>model</th>\n      <th>platform</th>\n      <th>position</th>\n      <th>processing</th>\n      <th>project</th>\n      <th>required</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# first tokenize the text so that punctions etc are removed\n",
    "def tokenize(text):\n",
    "    clean_text = re.sub('[^a-zA-Z 0-9]', '', text)\n",
    "    tokens = clean_text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "# df_new['description_tokenized'] = df_new['description'].apply(tokenize)\n",
    "\n",
    "# Learn from the vocab\n",
    "# using max_features to only have only top 20\n",
    "vect = CountVectorizer(encoding='utf-8', \n",
    "                        stop_words='english', \n",
    "                        tokenizer=tokenize,\n",
    "                        min_df=5,\n",
    "                        max_df=0.25,\n",
    "                        max_features=20\n",
    "                        )\n",
    "\n",
    "# get the sparse dtm (document term matrix) fit and transform in the same function\n",
    "dtm = vect.fit_transform(df_new['description'])\n",
    "\n",
    "# Convert the dtm into DatFrame for visibility\n",
    "dtm_df = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "\n",
    "print(dtm_df.shape)\n",
    "dtm_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0                                        description  \\\n",
       "0             0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1             1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2             2  b'As a Data Scientist you will be working on c...   \n",
       "3             3  b'$4,969 - $6,756 a monthContractUnder the gen...   \n",
       "4             4  b'Location: USA \\xe2\\x80\\x93 multiple location...   \n",
       "..          ...                                                ...   \n",
       "421         421  b\"About Us:\\nWant to be part of a fantastic an...   \n",
       "422         422  b'InternshipAt Uber, we ignite opportunity by ...   \n",
       "423         423  b'$200,000 - $350,000 a yearA million people a...   \n",
       "424         424  b\"SENIOR DATA SCIENTIST\\nJOB DESCRIPTION\\n\\nAB...   \n",
       "425         425  b'Cerner Intelligence is a new, innovative org...   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                      Data scientist    \n",
       "1                                     Data Scientist I   \n",
       "2                         Data Scientist - Entry Level   \n",
       "3                                       Data Scientist   \n",
       "4                                       Data Scientist   \n",
       "..                                                 ...   \n",
       "421                       Senior Data Science Engineer   \n",
       "422  2019 PhD Data Scientist Internship - Forecasti...   \n",
       "423                         Data Scientist - Insurance   \n",
       "424                              Senior Data Scientist   \n",
       "425                                     Data Scientist   \n",
       "\n",
       "                                           spacy_token  \n",
       "0    [b\"Job, Requirements:\\nConceptual, understandi...  \n",
       "1    [b'Job, Description\\n\\nAs, a, Data, Scientist,...  \n",
       "2    [b'As, a, Data, Scientist, you, will, be, work...  \n",
       "3    [b'$4,969, -, $, 6,756, a, monthContractUnder,...  \n",
       "4    [b'Location, :, USA, \\xe2\\x80\\x93, multiple, l...  \n",
       "..                                                 ...  \n",
       "421  [b\"About, Us:\\nWant, to, be, part, of, a, fant...  \n",
       "422  [b'InternshipAt, Uber, ,, we, ignite, opportun...  \n",
       "423  [b'$200,000, -, $, 350,000, a, yearA, million,...  \n",
       "424  [b\"SENIOR, DATA, SCIENTIST\\nJOB, DESCRIPTION\\n...  \n",
       "425  [b'Cerner, Intelligence, is, a, new, ,, innova...  \n",
       "\n",
       "[426 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>description</th>\n      <th>title</th>\n      <th>spacy_token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n      <td>Data scientist</td>\n      <td>[b\"Job, Requirements:\\nConceptual, understandi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n      <td>Data Scientist I</td>\n      <td>[b'Job, Description\\n\\nAs, a, Data, Scientist,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b'As a Data Scientist you will be working on c...</td>\n      <td>Data Scientist - Entry Level</td>\n      <td>[b'As, a, Data, Scientist, you, will, be, work...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n      <td>Data Scientist</td>\n      <td>[b'$4,969, -, $, 6,756, a, monthContractUnder,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n      <td>Data Scientist</td>\n      <td>[b'Location, :, USA, \\xe2\\x80\\x93, multiple, l...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>421</td>\n      <td>b\"About Us:\\nWant to be part of a fantastic an...</td>\n      <td>Senior Data Science Engineer</td>\n      <td>[b\"About, Us:\\nWant, to, be, part, of, a, fant...</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>422</td>\n      <td>b'InternshipAt Uber, we ignite opportunity by ...</td>\n      <td>2019 PhD Data Scientist Internship - Forecasti...</td>\n      <td>[b'InternshipAt, Uber, ,, we, ignite, opportun...</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>423</td>\n      <td>b'$200,000 - $350,000 a yearA million people a...</td>\n      <td>Data Scientist - Insurance</td>\n      <td>[b'$200,000, -, $, 350,000, a, yearA, million,...</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>424</td>\n      <td>b\"SENIOR DATA SCIENTIST\\nJOB DESCRIPTION\\n\\nAB...</td>\n      <td>Senior Data Scientist</td>\n      <td>[b\"SENIOR, DATA, SCIENTIST\\nJOB, DESCRIPTION\\n...</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>425</td>\n      <td>b'Cerner Intelligence is a new, innovative org...</td>\n      <td>Data Scientist</td>\n      <td>[b'Cerner, Intelligence, is, a, new, ,, innova...</td>\n    </tr>\n  </tbody>\n</table>\n<p>426 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 349.2 231.84\" width=\"349.2pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-05-07T23:09:34.398432</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 231.84 \nL 349.2 231.84 \nL 349.2 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 7.2 224.64 \nL 126.769219 224.64 \nL 126.769219 99.667461 \nL 7.2 99.667461 \nz\n\" style=\"fill:#dfe318;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 7.2 99.667461 \nL 126.769219 99.667461 \nL 126.769219 7.2 \nL 7.2 7.2 \nz\n\" style=\"fill:#37b878;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 126.769219 224.64 \nL 251.573937 224.64 \nL 251.573937 171.859616 \nL 126.769219 171.859616 \nz\n\" style=\"fill:#472f7d;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 251.573937 224.64 \nL 342 224.64 \nL 342 171.859616 \nL 251.573937 171.859616 \nz\n\" style=\"fill:#22a884;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 126.769219 171.859616 \nL 209.176269 171.859616 \nL 209.176269 118.293331 \nL 126.769219 118.293331 \nz\n\" style=\"fill:#21a585;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 209.176269 171.859616 \nL 279.149598 171.859616 \nL 279.149598 118.293331 \nL 209.176269 118.293331 \nz\n\" style=\"fill:#1f998a;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 279.149598 171.859616 \nL 342 171.859616 \nL 342 118.293331 \nL 279.149598 118.293331 \nz\n\" style=\"fill:#453581;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 126.769219 118.293331 \nL 185.691878 118.293331 \nL 185.691878 62.689578 \nL 126.769219 62.689578 \nz\n\" style=\"fill:#26818e;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 126.769219 62.689578 \nL 185.691878 62.689578 \nL 185.691878 7.2 \nL 126.769219 7.2 \nz\n\" style=\"fill:#433e85;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 185.691878 118.293331 \nL 265.903328 118.293331 \nL 265.903328 82.323883 \nL 185.691878 82.323883 \nz\n\" style=\"fill:#46c06f;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 265.903328 118.293331 \nL 342 118.293331 \nL 342 82.323883 \nL 265.903328 82.323883 \nz\n\" style=\"fill:#46327e;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 185.691878 82.323883 \nL 233.397967 82.323883 \nL 233.397967 42.052324 \nL 185.691878 42.052324 \nz\n\" style=\"fill:#63cb5f;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 185.691878 42.052324 \nL 233.397967 42.052324 \nL 233.397967 7.2 \nL 185.691878 7.2 \nz\n\" style=\"fill:#21a685;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 233.397967 82.323883 \nL 290.013839 82.323883 \nL 290.013839 57.828311 \nL 233.397967 57.828311 \nz\n\" style=\"fill:#25838e;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 290.013839 82.323883 \nL 342 82.323883 \nL 342 57.828311 \nL 290.013839 57.828311 \nz\n\" style=\"fill:#93d741;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 233.397967 57.828311 \nL 279.982373 57.828311 \nL 279.982373 31.565133 \nL 233.397967 31.565133 \nz\n\" style=\"fill:#481d6f;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 233.397967 31.565133 \nL 279.982373 31.565133 \nL 279.982373 7.2 \nL 233.397967 7.2 \nz\n\" style=\"fill:#2a788e;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 279.982373 57.828311 \nL 311.800598 57.828311 \nL 311.800598 23.394241 \nL 279.982373 23.394241 \nz\n\" style=\"fill:#1fa088;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 311.800598 57.828311 \nL 342 57.828311 \nL 342 23.394241 \nL 311.800598 23.394241 \nz\n\" style=\"fill:#423f85;opacity:0.8;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path clip-path=\"url(#p1c721da637)\" d=\"M 279.982373 23.394241 \nL 342 23.394241 \nL 342 7.2 \nL 279.982373 7.2 \nz\n\" style=\"fill:#9dd93b;opacity:0.8;\"/>\n   </g>\n   <g id=\"text_1\">\n    <!-- , -->\n    <g transform=\"translate(65.395547 164.913106)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 750 794 \nL 1409 794 \nL 1409 256 \nL 897 -744 \nL 494 -744 \nL 750 256 \nL 750 794 \nz\n\" id=\"DejaVuSans-2c\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-2c\"/>\n    </g>\n   </g>\n   <g id=\"text_2\">\n    <!-- and -->\n    <g transform=\"translate(57.577578 56.193106)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" id=\"DejaVuSans-64\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"61.279297\" xlink:href=\"#DejaVuSans-6e\"/>\n     <use x=\"124.658203\" xlink:href=\"#DejaVuSans-64\"/>\n    </g>\n   </g>\n   <g id=\"text_3\">\n    <!-- to -->\n    <g transform=\"translate(184.152047 201.009183)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"39.208984\" xlink:href=\"#DejaVuSans-6f\"/>\n    </g>\n   </g>\n   <g id=\"text_4\">\n    <!-- the -->\n    <g transform=\"translate(288.5815 201.009183)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-68\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"39.208984\" xlink:href=\"#DejaVuSans-68\"/>\n     <use x=\"102.587891\" xlink:href=\"#DejaVuSans-65\"/>\n    </g>\n   </g>\n   <g id=\"text_5\">\n    <!-- of -->\n    <g transform=\"translate(163.153213 147.835849)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" id=\"DejaVuSans-66\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"61.181641\" xlink:href=\"#DejaVuSans-66\"/>\n    </g>\n   </g>\n   <g id=\"text_6\">\n    <!-- . -->\n    <g transform=\"translate(242.573871 147.835849)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-2e\"/>\n    </g>\n   </g>\n   <g id=\"text_7\">\n    <!-- in -->\n    <g transform=\"translate(306.016986 147.835849)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"27.783203\" xlink:href=\"#DejaVuSans-6e\"/>\n    </g>\n   </g>\n   <g id=\"text_8\">\n    <!-- data -->\n    <g transform=\"translate(144.968048 93.250829)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-64\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"124.755859\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"163.964844\" xlink:href=\"#DejaVuSans-61\"/>\n    </g>\n   </g>\n   <g id=\"text_9\">\n    <!-- a -->\n    <g transform=\"translate(153.166486 37.704164)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-61\"/>\n    </g>\n   </g>\n   <g id=\"text_10\">\n    <!-- with -->\n    <g transform=\"translate(215.190572 103.067982)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 269 3500 \nL 844 3500 \nL 1563 769 \nL 2278 3500 \nL 2956 3500 \nL 3675 769 \nL 4391 3500 \nL 4966 3500 \nL 4050 0 \nL 3372 0 \nL 2619 2869 \nL 1863 0 \nL 1184 0 \nL 269 3500 \nz\n\" id=\"DejaVuSans-77\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-77\"/>\n     <use x=\"81.787109\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"109.570312\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"148.779297\" xlink:href=\"#DejaVuSans-68\"/>\n    </g>\n   </g>\n   <g id=\"text_11\">\n    <!-- - -->\n    <g transform=\"translate(302.147758 103.067982)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" id=\"DejaVuSans-2d\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n    </g>\n   </g>\n   <g id=\"text_12\">\n    <!-- for -->\n    <g transform=\"translate(202.669922 64.947479)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-66\"/>\n     <use x=\"35.205078\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"96.386719\" xlink:href=\"#DejaVuSans-72\"/>\n    </g>\n   </g>\n   <g id=\"text_13\">\n    <!-- or -->\n    <g transform=\"translate(204.430079 27.385537)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"61.181641\" xlink:href=\"#DejaVuSans-72\"/>\n    </g>\n   </g>\n   <g id=\"text_14\">\n    <!-- is -->\n    <g transform=\"translate(257.712153 72.835472)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"27.783203\" xlink:href=\"#DejaVuSans-73\"/>\n    </g>\n   </g>\n   <g id=\"text_15\">\n    <!-- our -->\n    <g transform=\"translate(307.723326 72.835472)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" id=\"DejaVuSans-75\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"61.181641\" xlink:href=\"#DejaVuSans-75\"/>\n     <use x=\"124.560547\" xlink:href=\"#DejaVuSans-72\"/>\n    </g>\n   </g>\n   <g id=\"text_16\">\n    <!-- will -->\n    <g transform=\"translate(248.43392 47.456097)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-77\"/>\n     <use x=\"81.787109\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"109.570312\" xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"137.353516\" xlink:href=\"#DejaVuSans-6c\"/>\n    </g>\n   </g>\n   <g id=\"text_17\">\n    <!-- on -->\n    <g transform=\"translate(250.462045 22.141941)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"61.181641\" xlink:href=\"#DejaVuSans-6e\"/>\n    </g>\n   </g>\n   <g id=\"text_18\">\n    <!-- ( -->\n    <g transform=\"translate(293.940704 43.370651)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" id=\"DejaVuSans-28\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-28\"/>\n    </g>\n   </g>\n   <g id=\"text_19\">\n    <!-- as -->\n    <g transform=\"translate(321.231549 43.370651)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"61.279297\" xlink:href=\"#DejaVuSans-73\"/>\n    </g>\n   </g>\n   <g id=\"text_20\">\n    <!-- business -->\n    <g transform=\"translate(289.19978 18.056496)scale(0.1 -0.1)\">\n     <defs>\n      <path d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" id=\"DejaVuSans-62\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-62\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-75\"/>\n     <use x=\"126.855469\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"178.955078\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"206.738281\" xlink:href=\"#DejaVuSans-6e\"/>\n     <use x=\"270.117188\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"331.640625\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"383.740234\" xlink:href=\"#DejaVuSans-73\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1c721da637\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# visualizing using the spacy tokens as visualization from CountVectorize is not known so far\n",
    "\n",
    "# importing the Counter module\n",
    "from collections import Counter\n",
    "import squarify\n",
    "\n",
    "\n",
    "# importing the count function first \n",
    "def count(tokens):\n",
    "    \"\"\"\n",
    "    Calculates some basic statistics about tokens in our corpus (i.e. corpus means collections text data)\n",
    "    \"\"\"\n",
    "    # stores the count of each token\n",
    "    word_counts = Counter()\n",
    "    \n",
    "    # stores the number of docs that each token appears in \n",
    "    appears_in = Counter()\n",
    "\n",
    "    total_docs = len(tokens)\n",
    "\n",
    "    for token in tokens:\n",
    "        # stores count of every appearance of a token \n",
    "        word_counts.update(token)\n",
    "        # use set() in order to not count duplicates, thereby count the num of docs that each token appears in\n",
    "        appears_in.update(set(token))\n",
    "\n",
    "    # build word count dataframe\n",
    "    temp = zip(word_counts.keys(), word_counts.values())\n",
    "    wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "    # rank the the word counts\n",
    "    wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "    total = wc['count'].sum()\n",
    "\n",
    "    # calculate the percent total of each token\n",
    "    wc['pct_total'] = wc['count'].apply(lambda token_count: token_count / total)\n",
    "\n",
    "    # calculate the cumulative percent total of word counts \n",
    "    wc = wc.sort_values(by='rank')\n",
    "    wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "\n",
    "    # create dataframe for document stats\n",
    "    t2 = zip(appears_in.keys(), appears_in.values())\n",
    "    ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "    \n",
    "    # merge word count stats with doc stats\n",
    "    wc = ac.merge(wc, on='word')\n",
    "\n",
    "    wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
    "\n",
    "    return wc.sort_values(by='rank')\n",
    "\n",
    "\n",
    "# finding the count for the spacy_tokens\n",
    "wc = count(df_new['spacy_token'])\n",
    "wc_top20 = wc[wc['rank'] <= 20]\n",
    "wc_top20\n",
    "\n",
    "# plot\n",
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'], alpha=0.8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english',\n",
    "                       ngram_range=(1,3),\n",
    "                       min_df=3,\n",
    "                       max_df=0.25,\n",
    "                       tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(426, 15237)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     0  0 2  0 2 yearsnrequirementsnxc2xbb         1    1 year  \\\n",
       "0  0.0  0.0                            0.0  0.000000  0.000000   \n",
       "1  0.0  0.0                            0.0  0.104846  0.064939   \n",
       "2  0.0  0.0                            0.0  0.000000  0.000000   \n",
       "3  0.0  0.0                            0.0  0.000000  0.000000   \n",
       "4  0.0  0.0                            0.0  0.000000  0.000000   \n",
       "\n",
       "   1 year experience  1 years  1 years experience   10  10 time  ...  \\\n",
       "0                0.0      0.0                 0.0  0.0      0.0  ...   \n",
       "1                0.0      0.0                 0.0  0.0      0.0  ...   \n",
       "2                0.0      0.0                 0.0  0.0      0.0  ...   \n",
       "3                0.0      0.0                 0.0  0.0      0.0  ...   \n",
       "4                0.0      0.0                 0.0  0.0      0.0  ...   \n",
       "\n",
       "   youxe2x80x99ll opportunity  youxe2x80x99ll work  \\\n",
       "0                         0.0                  0.0   \n",
       "1                         0.0                  0.0   \n",
       "2                         0.0                  0.0   \n",
       "3                         0.0                  0.0   \n",
       "4                         0.0                  0.0   \n",
       "\n",
       "   youxe2x80x99ll work closely  youxe2x80x99re  youxe2x80x99re looking  \\\n",
       "0                          0.0             0.0                     0.0   \n",
       "1                          0.0             0.0                     0.0   \n",
       "2                          0.0             0.0                     0.0   \n",
       "3                          0.0             0.0                     0.0   \n",
       "4                          0.0             0.0                     0.0   \n",
       "\n",
       "   youxe2x80x99re looking make  youxe2x80x99re ready  youxe2x80x99ve  \\\n",
       "0                          0.0                   0.0             0.0   \n",
       "1                          0.0                   0.0             0.0   \n",
       "2                          0.0                   0.0             0.0   \n",
       "3                          0.0                   0.0             0.0   \n",
       "4                          0.0                   0.0             0.0   \n",
       "\n",
       "   youxe2x80x99ve worked  yrs  \n",
       "0                    0.0  0.0  \n",
       "1                    0.0  0.0  \n",
       "2                    0.0  0.0  \n",
       "3                    0.0  0.0  \n",
       "4                    0.0  0.0  \n",
       "\n",
       "[5 rows x 15237 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>0 2</th>\n      <th>0 2 yearsnrequirementsnxc2xbb</th>\n      <th>1</th>\n      <th>1 year</th>\n      <th>1 year experience</th>\n      <th>1 years</th>\n      <th>1 years experience</th>\n      <th>10</th>\n      <th>10 time</th>\n      <th>...</th>\n      <th>youxe2x80x99ll opportunity</th>\n      <th>youxe2x80x99ll work</th>\n      <th>youxe2x80x99ll work closely</th>\n      <th>youxe2x80x99re</th>\n      <th>youxe2x80x99re looking</th>\n      <th>youxe2x80x99re looking make</th>\n      <th>youxe2x80x99re ready</th>\n      <th>youxe2x80x99ve</th>\n      <th>youxe2x80x99ve worked</th>\n      <th>yrs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.104846</td>\n      <td>0.064939</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 15237 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "# build the vocabulary, fit transform at the same time\n",
    "dtm = vect.fit_transform(df_new['description'])\n",
    "\n",
    "# Convert to dataframe\n",
    "dtm_df = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "print(dtm_df.shape)\n",
    "dtm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[0.        , 1.32442502, 1.35406024, 1.35406024, 1.35973857]]),\n",
       " array([[  0, 115, 206, 352,  42]]))"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm_df)\n",
    "\n",
    "# sample a doc from dtm to use as our query point\n",
    "doc = dtm_df.iloc[0].values\n",
    "\n",
    "# query using kneighbours\n",
    "nn.kneighbors([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b\"Job Requirements:\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\nHands on experience in SQL/Hive or similar programming language\\nMust show past work via GitHub, Kaggle or any other published article\\nMaster's degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\nApply Now\"\n\nb'Company Overview\\nAt Proofpoint, we have a passion for protecting people, data, and brands from today\\xe2\\x80\\x99s advanced threats and compliance risks. We hire the best people in the business to:\\nBuild and enhance our proven security platform\\nBlend innovation and speed in a constantly evolving cloud architecture\\nAnalyze new threats and offer deep insight through data-driven intel\\nCollaborate with customers to help solve their toughest security challenges\\nWe are singularly devoted to helping our customers protect what matters most. That\\xe2\\x80\\x99s why we\\xe2\\x80\\x99re a leader in next-generation cybersecurity\\xe2\\x80\\x94and why more than half of the Fortune 100 trust us as a security partner.\\nThe Role\\nDo you have a passion for applying machine learning to hard problems in new application areas? Do you keep up with the latest on GANs, ResNets, CNNs, RNNs, and Deep Reinforcement Learning but have also mastered the classics like SVM and Random Forest? Are you looking for the opportunity to work with a great team that combines algorithm design, software engineering, and domain knowledge into products that are first of their kind? If so, we are looking for you. We need a Data Scientist who will work on analyzing data from malicious actors\\nto help uncover cyber threats. Your primary focus will be applying your skills in various areas like anomaly detection, graph mining, clustering, and predictive analytics to help us build groundbreaking services that would revolutionize the industry.\\n\\nWe are a fast-paced, high-energy team where you will be given the opportunity to make a significant impact. The team has a solid engineering culture that values the craftsmanship of writing great software, enjoys learning, and solving big problems.\\nYour day-to-day\\nFeature engineering, building and optimizing classifiers, applying machine learning and deep learning expertise\\nBlending data from disparate sources, mining the resulting data lake to build models\\nContributing tested code to the team\\xe2\\x80\\x99s git repo and working with engineering to implement models efficiently\\nProcessing, cleansing and verifying integrity of data used for analysis\\nConducting ad-hoc analysis and innovation around data visualization\\n What you bring to the team\\nMinimum 1 year of professional experience in cybersecurity industry\\nExcellent understanding of machine learning algorithms, processes, tools and platforms including:\\nSupervised methods - Na\\xc3\\xafve Bayes, Logistic Regression, SVM, ConvNet, LSTM, Siamese Networks, etc.\\nUnsupervised methods - K-means, DBSCAN, T-SNE, Spectral Clustering, SOM, LSH, etc.\\nToolkits - numpy, scipy, scikit-learn, tensorflow, pytorch, keras, genism, vowpal wabbit, etc.\\nPython proficiency\\nGreat communication skills, ability to explain predictive analytics to non-technical audience\\nProficiency in data exploration techniques and tools, e.g. SQL, Hive, etc.\\nExcellent statistics, linear algebra, and optimization skills\\nMS in Statistics, Machine Learning, Applied Physics or Computer Science (or technical degree with commensurate industry experience). PhD preferred\\nWhy Proofpoint\\n\\nAs a customer focused and driven-to-win organization with leading edge products, there are many exciting reasons to join the Proofpoint team. We believe in hiring the best the brightest and cultivating a culture of collaboration and appreciation. As we continue to grow and expand globally, we understand that hiring the right people and treating them well is key to our success! We are a multi-national company with locations in 10 countries, with each location contributing to Proofpoint\\xe2\\x80\\x99s amazing culture!\\n#LI-JL3'\n\nb\"OpenX is seeking a Data Scientist to be responsible for executing critical R&D projects on a petabyte-scale dataset. This isn't an advanced analytics role. Simple linear & logistic regression won't cut it for most of the of problems we face. We're talking about cutting edge applications of Neural Networks, bagged & boosted decision trees, as well as highly customized optimization algorithms. We're looking for a Senior Data Scientist who:\\n\\n\\nCan translate requests from business and product into Data Science/ML problems\\nHas a track record of taking state-of-the-art advances from the literature and incorporating them into production systems\\nWorks well independently and as part of a team of people with diverse backgrounds\\n\\nKey Responsibilities\\n\\n\\nRapidly prototype models, including creation, training, and evaluation to drive business objectives, including:\\nOptimizing aspects of OpenX's programmatic ad exchange to maximize value for our buyers and sellers\\nLeveraging big data to unlock the potential of people based marketing\\nImplement production training and real-time model evaluation architectures in Google Cloud Platform\\nDesign and execute experiments to assess model performance\\nServe as a consultant for analysts across the organization\\n\\nRequired Qualifications\\n\\n\\nPh.D in Computer Science, Statistics, Physics, Mathematics, Operations Research or related field, or MS with 3+ years of experience\\nPractical experience with machine learning languages and tools such as python/pandas and tensorflow/pytorch\\nSolid background in machine learning/data science, control theory, signal processing, or image processing\\nFamiliarity with big data technologies such as SQL, Hadoop, Hive, Impala, Scala, Spark, etc\\n\\nDesired Characteristics\\n\\n\\nExperience with machine learning on GCP, AWS or Azure\\nExperience reporting findings to a broad audience\\n\\nCompany at a Glance\\n\\nOpenX is focused on unleashing the full economic potential of digital media companies. We do this by making digital advertising markets and technologies that are designed to deliver optimal value to publishers and advertisers on every ad served across all screens.\\n\\nAt OpenX, we have built a team that is uniquely experienced in designing and operating high-scale ad marketplaces, and we are constantly on the lookout for thoughtful, creative executors who are as fascinated as we are about finding new ways to apply a blend of market design, technical innovation, operational excellence, and empathetic partner service to the frontiers of digital advertising.\\n\\nOpenX Values\\n\\nOur five company values form a solid bedrock serving to define us as a group and guide the company. Our values remind us that how we do things often matters as much as what we do.\\n\\nWe are one\\n\\nOne team. No exceptions. We are a group of strong and diverse individuals unified by a clear common purpose.\\n\\nOur customers define us\\n\\nWe know our business flourishes or dies because of our customers.\\n\\nOpenX is mine\\n\\nWe are all owners of OpenX. We stake our personal and professional reputations on the excellence of our work.\\n\\nWe are an open book\\n\\nWe are eager to teach and share what we know with others.\\n\\nWe evolve fast\\n\\nWe take risks and confront failure openly. We recognize and repeat success aggressively. We actively seek out and provide constructive criticism. Defensiveness is for weaklings!\"\n\nb\"OpenX is seeking a Data Scientist to be responsible for executing critical R&D projects on a petabyte-scale dataset. This isn't an advanced analytics role. Simple linear & logistic regression won't cut it for most of the of problems we face. We're talking about cutting edge applications of Neural Networks, bagged & boosted decision trees, as well as highly customized optimization algorithms. We're looking for a Senior Data Scientist who:\\n\\n\\nCan translate requests from business and product into Data Science/ML problems\\nHas a track record of taking state-of-the-art advances from the literature and incorporating them into production systems\\nWorks well independently and as part of a team of people with diverse backgrounds\\n\\nKey Responsibilities\\n\\n\\nRapidly prototype models, including creation, training, and evaluation to drive business objectives, including:\\nOptimizing aspects of OpenX's programmatic ad exchange to maximize value for our buyers and sellers\\nLeveraging big data to unlock the potential of people based marketing\\nImplement production training and real-time model evaluation architectures in Google Cloud Platform\\nDesign and execute experiments to assess model performance\\nServe as a consultant for analysts across the organization\\n\\nRequired Qualifications\\n\\n\\nPh.D in Computer Science, Statistics, Physics, Mathematics, Operations Research or related field, or MS with 3+ years of experience\\nPractical experience with machine learning languages and tools such as python/pandas and tensorflow/pytorch\\nSolid background in machine learning/data science, control theory, signal processing, or image processing\\nFamiliarity with big data technologies such as SQL, Hadoop, Hive, Impala, Scala, Spark, etc\\n\\nDesired Characteristics\\n\\n\\nExperience with machine learning on GCP, AWS or Azure\\nExperience reporting findings to a broad audience\\n\\nCompany at a Glance\\n\\nOpenX is focused on unleashing the full economic potential of digital media companies. We do this by making digital advertising markets and technologies that are designed to deliver optimal value to publishers and advertisers on every ad served across all screens.\\n\\nAt OpenX, we have built a team that is uniquely experienced in designing and operating high-scale ad marketplaces, and we are constantly on the lookout for thoughtful, creative executors who are as fascinated as we are about finding new ways to apply a blend of market design, technical innovation, operational excellence, and empathetic partner service to the frontiers of digital advertising.\\n\\nOpenX Values\\n\\nOur five company values form a solid bedrock serving to define us as a group and guide the company. Our values remind us that how we do things often matters as much as what we do.\\n\\nWe are one\\n\\nOne team. No exceptions. We are a group of strong and diverse individuals unified by a clear common purpose.\\n\\nOur customers define us\\n\\nWe know our business flourishes or dies because of our customers.\\n\\nOpenX is mine\\n\\nWe are all owners of OpenX. We stake our personal and professional reputations on the excellence of our work.\\n\\nWe are an open book\\n\\nWe are eager to teach and share what we know with others.\\n\\nWe evolve fast\\n\\nWe take risks and confront failure openly. We recognize and repeat success aggressively. We actively seek out and provide constructive criticism. Defensiveness is for weaklings!\"\n\nb'Job Description\\n\\n5-10 years hands-on experience in forecasting, Machine learning, and/or optimization modeling, and simulation.Working knowledge of predictive modeling and ML tools (scikit, R)Experience with data acquisition tools (e.g. SQL, Apache Spark etc.), large datasets (Hadoop) and data miningProgramming language (Java, scripting language like Python.Good understanding of NLP conceptsHave understanding of machine learning conceptsHave understanding of Hadoop (specifically HIVE/HDFS/Kafka)Fine on programming concepts \\xe2\\x80\\x93 pythonStronger skills on image analysis and more experience in Machine Learning / Deep Learning\\n\\nQualifications\\n\\nnull\\n\\nAdditional Information\\n\\nAll your information will be kept confidential according to EEO guidelines.'\n"
     ]
    }
   ],
   "source": [
    "# the document is most similar to 115\n",
    "# i.e.\n",
    "\n",
    "print(df_new['description'][0])\n",
    "print()\n",
    "print(df_new['description'][115])\n",
    "print()\n",
    "print(df_new['description'][206])\n",
    "print()\n",
    "print(df_new['description'][352])\n",
    "print()\n",
    "print(df_new['description'][42])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "name": "python370jvsc74a57bd0c751e3dba1c0ae6d681c8fd9e4eb9597bc490d2dc541e0c49930039039a54e24",
   "display_name": "Python 3.7.0 64-bit ('U4-S1-NLP': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}